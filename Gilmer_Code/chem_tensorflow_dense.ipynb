{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note of `chem_tensorflow_dense.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program is downloaded at Jan 25<sup>th</sup>, 2018 at github repository [gated-graph-neural-network-samples](https://github.com/Microsoft/gated-graph-neural-network-samples) maintained by Microsoft. The commit code hash is [049a8a2](https://github.com/Microsoft/gated-graph-neural-network-samples/commit/049a8a2c51e74c1bd75f4873fbe1c9beff7250a2).\n",
    "\n",
    "This job is tested at 2018-01-25-12-21-43.\n",
    "\n",
    "This jupyter notebook is not executable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code has been slightly modified. At line 48-49, there should exists a missing key `'task_example_ratios'` in dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `docopt` Option Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first try to explain how main program works. At line 194 in `chem_tensorflow_dense.py`, the main program is the following codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    args = docopt(__doc__)\n",
    "    try:\n",
    "        model = DenseGGNNChemModel(args)\n",
    "        model.train()\n",
    "    except:\n",
    "        typ, value, tb = sys.exc_info()\n",
    "        traceback.print_exc()\n",
    "        pdb.post_mortem(tb)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the line 2 above, the program parse command-line inputs. These inputs are defined at line 2 in `chem_tensorflow_dense.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Usage:\n",
    "    chem_tensorflow_dense.py [options]\n",
    "\n",
    "Options:\n",
    "    -h --help                Show this screen.\n",
    "    --config-file FILE       Hyperparameter configuration file path (in JSON format)\n",
    "    --config CONFIG          Hyperparameter configuration dictionary (in JSON format)\n",
    "    --log_dir NAME           log dir name\n",
    "    --data_dir NAME          data dir name\n",
    "    --restore FILE           File to restore weights from.\n",
    "    --freeze-graph-model     Freeze weights of graph model components.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information of how program interprets the command line, we refer to the github page of [docopt](https://github.com/docopt/docopt). What we should know is that these options are stored in a dictionary `args`, which has keys like `--config-file` and `--config`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abnormal Termination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In line 199-202 of `chem_tensorflow_dense.py`, this program defines how the program behaves when the training is not successful. The following code is an example that how the program works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first generate a fail information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, traceback\n",
    "try:\n",
    "    lst.index(\"a\")\n",
    "except:\n",
    "    typ, value, tb = sys.exc_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error is equal to the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-03ef573e1727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lst' is not defined"
     ]
    }
   ],
   "source": [
    "lst.index(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`typ`, `value` is easily defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NameError"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NameError(\"name 'lst' is not defined\")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traceback information is stored in `tb`. To retain the traceback output, we can use the following code to print the information to standard output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-42-b564f2ba8832>\", line 3, in <module>\n",
      "    lst.index(\"a\")\n",
      "NameError: name 'lst' is not defined\n"
     ]
    }
   ],
   "source": [
    "traceback.print_exception(typ, value, tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code `traceback.print_exc()` is shorthand for the above code. It can't be used in the new cells in jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `pdb.post_mortem(tb)`, it is a kind of debugging technique. We don't discuss that in deep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Inherition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From then we start to explore classes `DenseGGNNChemModel` and class `ChemModel`. These two classes are defined seperately in `chem_tensorflow_dense.py` and `chem_tensorflow.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, `DenseGGNNChemModel` class inherited all the methods in `ChemModel`. This inherition is coded as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Following code starting from Line 38 in `chem_tensorflow_dense.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseGGNNChemModel(ChemModel):\n",
    "    def __init__(self, args):\n",
    "        super().__init__(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These code means that when loading this class, all the arguments (`ChemModel`) will be loaded by `super()`, importing `args` (obtained by `docopt` package) as the arguments loaded to the inherited class (`ChemModel`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only the methods are inherited, but also the parameters are inherited. The parameters in `chem_tensorflow_dense.py` is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Following code starting from Line 43 in `chem_tensorflow_dense.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def default_params(cls):\n",
    "        params = dict(super().default_params())\n",
    "        params.update({\n",
    "                        'batch_size': 256,\n",
    "                        'graph_state_dropout_keep_prob': 1.,\n",
    "                        # Ajz34\n",
    "                        'task_sample_ratios': {},\n",
    "                      })\n",
    "        return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These default parameters are updated based on the following code in `chem_tensorflow.py`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Following code starting from Line 18 in `chem_tensorflow.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def default_params(cls):\n",
    "        return {\n",
    "            'num_epochs': 3000,\n",
    "            'patience': 25,\n",
    "            'learning_rate': 0.0001,\n",
    "            'clamp_gradient_norm': 1.0,\n",
    "            'out_layer_dropout_keep_prob': 1.0,\n",
    "\n",
    "            'hidden_size': 100,\n",
    "            'num_timesteps': 4,\n",
    "            'use_graph': True,\n",
    "\n",
    "            'tie_fwd_bkwd': True,\n",
    "            'task_ids': [0],\n",
    "\n",
    "            'random_seed': 0,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These methods are classified in `classmethod`. For the discussion of the difference of `classmethod` and `staticmethod`, we refer to this [stackoverflow link](https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class `ChemModel` Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection, we will observe what `ChemModel` Initialization process actually does. The code discussed here is in method `ChemModel.__init__` the file `chem_tensorflow.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect argument things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Following code starting from Line 39 in `chem_tensorflow.py`. 8 space indentation is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect argument things:\n",
    "data_dir = ''\n",
    "if '--data_dir' in args and args['--data_dir'] is not None:\n",
    "    data_dir = args['--data_dir']\n",
    "self.data_dir = data_dir\n",
    "\n",
    "self.run_id = \"_\".join([time.strftime(\"%Y-%m-%d-%H-%M-%S\"), str(os.getpid())])\n",
    "log_dir = args.get('--log_dir') or '.'\n",
    "self.log_file = os.path.join(log_dir, \"%s_log.json\" % self.run_id)\n",
    "self.best_model_file = os.path.join(log_dir, \"%s_model_best.pickle\" % self.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the code above:\n",
    "* Line 2-5: If inputed command-line arguments includes `data_dir`, then all the outputs should be in `./data_dir`; otherwise, all the outputs are dumped in the current directory. The example is listed in the cell beneath.\n",
    "* Line 7: Defines the job's id number. All the outputs then have an id number. In my implementation, the job's id is `2018-01-25-12-21-43_9839`. How the id be generated is also listed in the cell beneath.\n",
    "* Line 8: Defines log directory. If not defined when executing program in command-line, then `args.get('--log_dir')` returns `None`; consequently, the log files will be dumped to current directory `.`. \n",
    "* Line 9-10: Defines path of log file and best model parameters during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name\n",
      "data_dir/file_name\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.join(\"\", \"file_name\"))\n",
    "print(os.path.join(\"data_dir\", \"file_name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-25-16-17-44\n",
      "10091\n"
     ]
    }
   ],
   "source": [
    "import time, os\n",
    "print(time.strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "print(str(os.getpid()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None or '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Following code starting from Line 50 in `chem_tensorflow.py`. 8 space indentation is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect parameters:\n",
    "params = self.default_params()\n",
    "config_file = args.get('--config-file')\n",
    "if config_file is not None:\n",
    "    with open(config_file, 'r') as f:\n",
    "        params.update(json.load(f))\n",
    "config = args.get('--config')\n",
    "if config is not None:\n",
    "    params.update(json.loads(config))\n",
    "self.params = params\n",
    "with open(os.path.join(log_dir, \"%s_params.json\" % self.run_id), \"w\") as f:\n",
    "    json.dump(params, f)\n",
    "print(\"Run %s starting with following parameters:\\n%s\" % (self.run_id, json.dumps(self.params)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the code above:\n",
    "* Line 4-9: Note that `json.load` and `json.loads` is two different functions, though they work quite similarly. Generally speaking, file can be input to `json.load` (which can be parsed by `file.read()`), as well as strings can be input to `json.loads`. More information at [Python's documentation on json](https://docs.python.org/2/library/json.html).\n",
    "* Line 10-11: Defines path of parameters for learning utility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Following code starting from Line 64 in `chem_tensorflow.py`. 8 space indentation is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data:\n",
    "self.max_num_vertices = 0\n",
    "self.num_edge_types = 0\n",
    "self.annotation_size = 0\n",
    "self.train_data = self.load_data(\"molecules_train.json\", is_training_data=True)\n",
    "self.valid_data = self.load_data(\"molecules_valid.json\", is_training_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the code above:\n",
    "* Line 4-5: The data files `molecules_train.json` and `molecules_valid.json` are generated by the previous program `get_data.py`.\n",
    "<a id=\"ref_load_data\"></a>\n",
    "* Class function [`load_data`](#load_data) will be discussed later. This function also defines `self.max_num_vertices`, `self.num_edge_types` and `annotation_size`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the actual model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Following code starting from Line 71 in `chem_tensorflow.py`. 8 space indentation is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the actual model\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "self.graph = tf.Graph()\n",
    "self.sess = tf.Session(graph=self.graph, config=config)\n",
    "with self.graph.as_default():\n",
    "    random.seed(params['random_seed'])\n",
    "    np.random.seed(params['random_seed'])\n",
    "    tf.set_random_seed(params['random_seed'])\n",
    "    self.placeholders = {}\n",
    "    self.weights = {}\n",
    "    self.ops = {}\n",
    "    self.make_model()\n",
    "    self.make_train_step()\n",
    "\n",
    "    # Restore/initialize variables:\n",
    "    restore_file = args.get('--restore')\n",
    "    if restore_file is not None:\n",
    "        self.restore_model(restore_file)\n",
    "    else:\n",
    "        self.initialize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the code above:\n",
    "* Line 3: To understand `tf.ConfigProto().gpu_options.allow_growth = True`, we need to inspect the source code of tensorflow [`config.proto`](https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/core/protobuf/config.proto) and search for `allow_growth`. This line of code means that we initialize training with small usage of memory in GPU, instead of pre-allocate the whole memory space. During training, the memory may grow larger and larger. Since GPU memory is allocated dynamically, [memory leaking is possible](http://blog.csdn.net/u012436149/article/details/53837651).\n",
    "* Line 5: This line of code is equal to `self.sess = tf.Session(config=config)`. However, since the `self.graph` would be updated by the actions later, so we also define `self.graph` here.\n",
    "* Line 7-9: Set random seeds. 0 as default, defined by line 33 in `chem_tensorflow.py`.\n",
    "* Line 13-21: All these functions in the class should be explained later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now, the initialization of `ChemModel` class is finished. However, many functions in this initialization hasn't been defined. From then on, we need to know how these variables are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions in `ChemModel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load_data\"></a>\n",
    "### Function `load_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `load_data` was mentioned [before](#ref_load_data). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Following code starting from Line 93 in `chem_tensorflow.py`. 4 space indentation is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(self, file_name, is_training_data: bool):\n",
    "    full_path = os.path.join(self.data_dir, file_name)\n",
    "\n",
    "    print(\"Loading data from %s\" % full_path)\n",
    "    with open(full_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    restrict = self.args.get(\"--restrict_data\")\n",
    "    if restrict is not None and restrict > 0:\n",
    "        data = data[:restrict]\n",
    "\n",
    "    # Get some common data out:\n",
    "    num_fwd_edge_types = 0\n",
    "    for g in data:\n",
    "        self.max_num_vertices = max(self.max_num_vertices, max([v for e in g['graph'] for v in [e[0], e[2]]]))\n",
    "        num_fwd_edge_types = max(num_fwd_edge_types, max([e[1] for e in g['graph']]))\n",
    "    self.num_edge_types = max(self.num_edge_types, num_fwd_edge_types * (1 if self.params['tie_fwd_bkwd'] else 2))\n",
    "    self.annotation_size = max(self.annotation_size, len(data[0][\"node_features\"][0]))\n",
    "\n",
    "    return self.process_raw_graphs(data, is_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the code above:\n",
    "* Line 15-18: These are simple searching for maximum graph or molecule information. \n",
    "  * Line 15-16: Count maximum vertices numbers (atom numbers if hydrogen is included, or heavy atom numbers otherwise) and edge types. Frankly speaking, this process may be inefficient, for we have to go through the whole data again. We have already read all the data when loading `get_data.py`. This process can be implemented in `get_data.py` to decrease data I/O time waste.\n",
    "  * `e in g['graph']`: `e` should be similar to `[0, 2, 1]`. `e[0]`, `e[2]` are the number of atom, while `e[1]` is the bond type.\n",
    "  * Line 17: Since we just consider undirected graph here, so the edge types should be 4. If directed graph here, 8 instead.\n",
    "  * Line 18: Count of atom type. 5 here.\n",
    "  * Line 20: The function actually runs is not in line 119 `chem_tensorflow.py`, but in line 112 in `chem_tensorflow_dense.py`. This is function override, which is not apparent in vim editor, but appearant in IDE environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"process_raw_graphs\"></a>\n",
    "### Function `process_raw_graphs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Following code starting from Line 112 in `chem_tensorflow_dense.py`. 4 space indentation is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raw_graphs(self, raw_data: Sequence[Any], is_training_data: bool) -> Any:\n",
    "    bucket_sizes = np.array(list(range(4, 28, 2)) + [29])\n",
    "    bucketed = defaultdict(list)\n",
    "    x_dim = len(raw_data[0][\"node_features\"][0])\n",
    "    for d in raw_data:\n",
    "        chosen_bucket_idx = np.argmax(bucket_sizes > max([v for e in d['graph']\n",
    "                                                            for v in [e[0], e[2]]]))\n",
    "        chosen_bucket_size = bucket_sizes[chosen_bucket_idx]\n",
    "        bucketed[chosen_bucket_idx].append({\n",
    "            'adj_mat': graph_to_adj_mat(d['graph'], chosen_bucket_size, self.num_edge_types, self.params['tie_fwd_bkwd']),\n",
    "            'init': d[\"node_features\"] + [[0 for _ in range(x_dim)] for __ in\n",
    "                                          range(chosen_bucket_size - len(d[\"node_features\"]))],\n",
    "            'labels': [d[\"targets\"][task_id][0] for task_id in self.params['task_ids']],\n",
    "        })\n",
    "\n",
    "    if is_training_data:\n",
    "        for (bucket_idx, bucket) in bucketed.items():\n",
    "            np.random.shuffle(bucket)\n",
    "            for task_id in self.params['task_ids']:\n",
    "                task_sample_ratio = self.params['task_sample_ratios'].get(str(task_id))\n",
    "                if task_sample_ratio is not None:\n",
    "                    ex_to_sample = int(len(bucket) * task_sample_ratio)\n",
    "                    for ex_id in range(ex_to_sample, len(bucket)):\n",
    "                        bucket[ex_id]['labels'][task_id] = None\n",
    "\n",
    "    bucket_at_step = [[bucket_idx for _ in range(len(bucket_data) // self.params['batch_size'])]\n",
    "                      for bucket_idx, bucket_data in bucketed.items()]\n",
    "    bucket_at_step = [x for y in bucket_at_step for x in y]\n",
    "\n",
    "    return (bucketed, bucket_sizes, bucket_at_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is sample output from function `process_raw_graphs` if the .json file only includes the first two molecules in `molecules_train.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "(defaultdict(<class 'list'>, {0: [{'adj_mat': array([[[0., 0., 1., 1.],\n",
    "        [0., 0., 0., 0.],\n",
    "        [1., 0., 0., 0.],\n",
    "        [1., 0., 0., 0.]],\n",
    "\n",
    "       [[0., 1., 0., 0.],\n",
    "        [1., 0., 0., 0.],\n",
    "        [0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0.]]]), 'labels': [-0.3917742606773419], 'init': [[0, 1, 0, 0, 0], [0, 0, 0, 1, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0]]}], 1: [{'adj_mat': array([[[0., 1., 1., 1., 1., 0.],\n",
    "        [1., 0., 0., 0., 0., 1.],\n",
    "        [1., 0., 0., 0., 0., 0.],\n",
    "        [1., 0., 0., 0., 0., 0.],\n",
    "        [1., 0., 0., 0., 0., 0.],\n",
    "        [0., 1., 0., 0., 0., 0.]],\n",
    "\n",
    "       [[0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0.]]]), 'labels': [-0.7729827193116501], 'init': [[0, 1, 0, 0, 0], [0, 0, 0, 1, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0]]}]}), array([ 4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 29]), [])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
